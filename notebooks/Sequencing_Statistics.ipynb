{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Compute GISAID statistics\n",
      "--------------------------------------------------------------------------------\n",
      "Command: /home/dan/.miniconda3/envs/nomads/lib/python3.7/site-packages/ipykernel_launcher.py -f /home/dan/.local/share/jupyter/runtime/kernel-8ae9e148-99ed-407d-b843-6f2e7beb9b56.json\n",
      "Run on host: PATH\n",
      "Operating system: Linux\n",
      "Machine: x86_64\n",
      "Started at: 2021-05-19 10:03:59\n",
      "================================================================================\n",
      "Preparing directories...\n",
      "  Rampart directory: /media/dan/Master/WGS/2_SampleList_and_Rampart\n",
      "  Artic directory: /media/dan/Master/WGS/3_Artic_Output\n",
      "  GISAID directory: /media/dan/Master/WGS/5_GISAID\n",
      "Done.\n",
      "\n",
      "Examining directory contents...\n",
      "  Run\tNo. samples\n",
      "  C07\t19\n",
      "  Total runs: 1\n",
      "  Total samples: 19\n",
      "Done.\n",
      "\n",
      "Loading sample list details from Samples_Sequenced.csv...\n",
      "    931 PCR reactions have been performed consisting of...\n",
      "        27 Controls\n",
      "        903 Samples, of which....\n",
      "            835 are unique\n",
      "Removing samples that have not been sequenced\n",
      "    755 sequencing reactions have been performed consisting of...\n",
      "        24 Controls\n",
      "        730 Samples, of which....\n",
      "            676 are unique\n",
      "Done.\n",
      "\n",
      "Computing sequencing statistics...\n",
      "  Run  Samples/Complete\n",
      "  C07 19/19\n",
      "Done.\n",
      "    All sequence IDs are unique\n",
      "\n",
      "Statistics for a total of 19 samples have been calculated\n",
      "    Data output to intermediates/gisaid.csv\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Compute statistics for GISAID submission\n",
    "# ----------------------------------------\n",
    "#\n",
    "# Example usage:\n",
    "#   python run_gisaid-statistics.py -d data/WGS\n",
    "#\n",
    "# JHendry, 2021/01/01\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "import datetime\n",
    "import getopt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gisaid import *\n",
    "\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Compute GISAID statistics\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Command: %s\" % \" \".join(sys.argv))\n",
    "print(\"Run on host: %s\" % os.uname().nodename)\n",
    "print(\"Operating system: %s\" % os.uname().sysname)\n",
    "print(\"Machine: %s\" % os.uname().machine)\n",
    "print(\"Started at: %s\" % datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"=\" * 80)\n",
    "start_time = time.time()\n",
    "\n",
    "data_dir=\"/media/dan/Master/WGS/\"\n",
    "\n",
    "# # PARSE CLI INPUT\n",
    "# print(\"Parsing command line inputs...\")\n",
    "# try:\n",
    "#     opts, args = getopt.getopt(sys.argv[1:], \":d:\")\n",
    "# except getopt.GetoptError:\n",
    "#     print(\"  Error parsing options.\")\n",
    "#     sys.exit(2)\n",
    "# for opt, value in opts:\n",
    "#     if opt == \"-d\":\n",
    "#         data_dir = value\n",
    "#         print(\"  Data directory: %s\" % data_dir)\n",
    "#     else:\n",
    "#         print(\"  Parameter %s not recognized.\" % opt)\n",
    "#         sys.exit(2)\n",
    "# print(\"Done.\")\n",
    "# print(\"\")\n",
    "\n",
    "\n",
    "# PREPARE DIRECTORIES\n",
    "print(\"Preparing directories...\")\n",
    "rampart_dir = os.path.join(data_dir, \"2_SampleList_and_Rampart\")\n",
    "artic_dir = os.path.join(data_dir, \"3_Artic_Output\")\n",
    "gisaid_dir = os.path.join(data_dir, \"5_GISAID\")\n",
    "if not os.path.isdir(gisaid_dir):\n",
    "    os.makedirs(gisaid_dir)\n",
    "print(\"  Rampart directory: %s\" % rampart_dir)\n",
    "print(\"  Artic directory: %s\" % artic_dir)\n",
    "print(\"  GISAID directory: %s\" % gisaid_dir)\n",
    "print(\"Done.\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# EXAMINE CONTENTS\n",
    "print(\"Examining directory contents...\")\n",
    "contents_dt = {}\n",
    "rs = os.listdir(artic_dir)\n",
    "for r in os.listdir(artic_dir):\n",
    "    if os.path.isdir(os.path.join(artic_dir, r)) and r.startswith(\"C\"):\n",
    "        d = os.path.join(artic_dir, r, \"processed\")\n",
    "        n_samples = sum([1 for s in os.listdir(d) \n",
    "                         if os.path.isdir(os.path.join(d, s))])\n",
    "        contents_dt[r] = n_samples\n",
    "print(\"  Run\\tNo. samples\")\n",
    "for d, n in contents_dt.items():\n",
    "    print(\"  %s\\t%d\" % (d, n))\n",
    "print(\"  Total runs: %d\" % len(contents_dt.keys()))\n",
    "print(\"  Total samples: %d\" % sum(contents_dt.values()))\n",
    "print(\"Done.\")\n",
    "print(\"\")\n",
    "\n",
    "# Prepare storage\n",
    "dts = [] #data per sample\n",
    "dtr = [] #data per run\n",
    "\n",
    "# LOAD SAMPLE METADATA\n",
    "print(\"Loading sample list details from Samples_Sequenced.csv...\")\n",
    "samples_df = pd.read_csv(os.path.join(rampart_dir, \"Samples_Sequenced.csv\"))\n",
    "print(\"    %s PCR reactions have been performed consisting of...\" % samples_df.shape[0])\n",
    "print(\"        %s Controls\" % samples_df[samples_df.Type=='Control'].shape[0])\n",
    "print(\"        %s Samples, of which....\" % samples_df[samples_df.Type=='Sample'].shape[0])\n",
    "print(\"            %s are unique\" % samples_df[samples_df.Type=='Sample'][\"SampleID\"].unique().shape[0])\n",
    "\n",
    "print(\"Removing samples that have not been sequenced\")\n",
    "seqsamples_df = samples_df[samples_df.SeqRun.notnull()]\n",
    "print(\"    %s sequencing reactions have been performed consisting of...\" % seqsamples_df.shape[0])\n",
    "print(\"        %s Controls\" % seqsamples_df[seqsamples_df.Type=='Control'].shape[0])\n",
    "print(\"        %s Samples, of which....\" % seqsamples_df[seqsamples_df.Type=='Sample'].shape[0])\n",
    "print(\"            %s are unique\" % seqsamples_df[seqsamples_df.Type=='Sample'][\"SampleID\"].unique().shape[0])\n",
    "# Map from Unique ID to barcode ID\n",
    "sample_dt = { row[\"SeqID\"]: row[\"SeqBarcode\"] for _, row in seqsamples_df.iterrows() }\n",
    "print(\"Done.\")\n",
    "print(\"\")\n",
    "\n",
    "# COMPUTE SEQUENCING STATISTICS\n",
    "print(\"Computing sequencing statistics...\")\n",
    "\n",
    "# Iterate over runs\n",
    "print(\"  Run  Samples/Complete\")\n",
    "for r in rs:\n",
    "    \n",
    "    # Define run directory\n",
    "    run_dir = os.path.join(artic_dir, r)\n",
    "    if os.path.isdir(run_dir) and r.startswith(\"C\"):\n",
    "        d = os.path.join(run_dir, \"processed\")\n",
    "        \n",
    "        #Dictionary for a count of the number of reads that are unclassified\n",
    "        stats_run = {}\n",
    "        stats_run[\"SeqRun\"] = r\n",
    "        \n",
    "        #Need to count the number of unclassified reads just once per run\n",
    "        unclass_dir = os.path.join(d.replace(\"processed\", \"fastq/unclassified\"))\n",
    "        try:\n",
    "            t = 0 #count number of reads\n",
    "            for h, u in enumerate(os.listdir(unclass_dir)): #for each fastq\n",
    "                current = calc_fastq_total_reads(os.path.join(unclass_dir, u))\n",
    "                t = t+current\n",
    "            stats_run.update({\"total_reads\": t})\n",
    "        except:\n",
    "            stats_run.update({\"total_reads\": 0})\n",
    "        \n",
    "        # Store unclass results\n",
    "        dtr.append(stats_run)\n",
    "        \n",
    "        #Iterate over samples\n",
    "        n_total = len(os.listdir(d))\n",
    "        for i, s in enumerate(os.listdir(d)):\n",
    "            \n",
    "            # Print progress\n",
    "            sys.stdout.write(\"\\r\")\n",
    "            sys.stdout.flush()\n",
    "            sys.stdout.write(\"  %s %d/%d\" % (r, i+1, n_total))\n",
    "            \n",
    "            # Define sample directory\n",
    "            sample_dir = os.path.join(d, s)\n",
    "            \n",
    "            # Define sample barcode\n",
    "            b = sample_dt[s]\n",
    "            \n",
    "            # Identifiers\n",
    "            stats_dt = {}\n",
    "            stats_dt[\"SeqRun\"] = r\n",
    "            stats_dt[\"SeqID\"] = s\n",
    "            stats_dt[\"SeqBarcode\"] = b\n",
    "\n",
    "            # Calc. most statistics from coverage file\n",
    "            coverage_df = load_coverage_files(sample_dir)\n",
    "            stats_dt.update(calc_gisaid_stats(coverage_df))\n",
    "            \n",
    "            # Calc. Ns per 100kbp from consensus FASTA\n",
    "            consensus_path = os.path.join(sample_dir, \"%s.consensus.fasta\" % s)\n",
    "            ns_per_100kbp = calc_ns_per_100kbp(consensus_path, verbose=False)\n",
    "            stats_dt.update({\"ns_per_100kbp\": ns_per_100kbp})\n",
    "            \n",
    "            # Identify fastq files for analysis\n",
    "            b_fn = os.path.join(d.replace(\"processed\", \"fastq\"), \"C%02d_barcode%02d.fastq\" % (int(r[1:]), b))\n",
    "            try:\n",
    "                # Calc. sequencing depth from .fastq\n",
    "                sequencing_depth_avg_fastq = calc_avg_seq_depth(b_fn, genome_length=stats_dt[\"ref_genome_length\"])\n",
    "                stats_dt.update({\"sequencing_depth_avg_fastq\": sequencing_depth_avg_fastq})\n",
    "                # Calc. number of reads per barcode\n",
    "                total_reads = calc_fastq_total_reads(b_fn)\n",
    "                stats_dt.update({\"total_reads\": total_reads})\n",
    "            except:\n",
    "                stats_dt.update({\"sequencing_depth_avg_fastq\": 0})\n",
    "            \n",
    "            # Store\n",
    "            dts.append(stats_dt)\n",
    "        \n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\n\")\n",
    "        \n",
    "# Create data frame\n",
    "gisaid_df = pd.DataFrame(dts)\n",
    "print(\"Done.\")\n",
    "\n",
    "#Check that all the sequence IDs are unique\n",
    "if len(gisaid_df[\"SeqID\"]) == len(set(gisaid_df[\"SeqID\"])):\n",
    "    print(\"    All sequence IDs are unique\")\n",
    "else:\n",
    "    print(\"    Duplicate sequence IDs identified\")\n",
    "    l_func = lambda x, y: list((set(x)- set(y))) + list((set(y)- set(x))) \n",
    "    non_match = l_func(gisaid_df[\"SeqID\"], gisaid_df[\"SeqID\"].unique()) \n",
    "    print(\"    Non-match elements: \", non_match)\n",
    "    print(\"Exiting script\")\n",
    "    exit()\n",
    "print(\"\")\n",
    "print(\"Statistics for a total of %s samples have been calculated\" % gisaid_df.shape[0])\n",
    "gisaid_fn = \"intermediates/gisaid.csv\"\n",
    "gisaid_df.to_csv(os.path.join(gisaid_dir, gisaid_fn), index=False)\n",
    "print(\"    Data output to %s\" % gisaid_fn)\n",
    "print(\"Done.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Combining with other data outputs\n",
      "  PANGO and nextclade files found. Reading in data\n",
      "  A total of 50 sequence ids do not match between gisaid and PANGO\n",
      "  Merging gisaid (n=19), pango (n=69) and nextclade (n=69) data together\n",
      "  Total remaining records = 19\n",
      "  Removing unwanted column headings from final summary file of samples sequenced\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find the other stats files for merging\n",
    "print(\"-\" * 80)\n",
    "print(\"Combining with other data outputs\")\n",
    "if os.path.isfile(os.path.join(gisaid_dir,\"intermediates/lineage_report.csv\")) and os.path.isfile(os.path.join(gisaid_dir,\"intermediates/nextclade.csv\")):\n",
    "    print (\"  PANGO and nextclade files found. Reading in data\")\n",
    "    pango_df = pd.read_csv(os.path.join(gisaid_dir, \"intermediates/lineage_report.csv\"))\n",
    "    nextclade_df = pd.read_csv(os.path.join(gisaid_dir, \"intermediates/nextclade.csv\"), sep=';')\n",
    "elif os.path.isfile(os.path.join(gisaid_dir,\"intermediates/lineage_report.csv\")):\n",
    "    print (\"  Only PANGO file found. Exiting script\")\n",
    "    exit()\n",
    "elif os.path.isfile(os.path.join(gisaid_dir,\"intermediates/nextclade.csv\")):\n",
    "    print (\"  Only nextclade file found. Exiting script\")\n",
    "    exit()\n",
    "else:\n",
    "    print (\"  PANGO and nextclade files not found. Exiting script\")\n",
    "    exit()\n",
    "    \n",
    "#Check that all sequences are represented. If not this suggests that some of the fasta concatenation has failed or that the wrong sequence name has been used\n",
    "l_func = lambda x, y: list((set(x)- set(y))) + list((set(y)- set(x))) \n",
    "non_match_gp = l_func(gisaid_df[\"SeqID\"], pango_df[\"taxon\"]) \n",
    "non_match_gn = l_func(gisaid_df[\"SeqID\"], nextclade_df[\"seqName\"]) \n",
    "if len(non_match_gp) > 0 :\n",
    "    print(\"  A total of %s sequence ids do not match between gisaid and PANGO\" % len(non_match_gp))\n",
    "    #exit()\n",
    "elif len(non_match_gn) > 0 :\n",
    "    print(\"  A total of %s sequence ids do not match between gisaid and nextclade\" % len(non_match_gn))\n",
    "    #exit()\n",
    "else:\n",
    "    print(\"  All sequences match across the three files\")\n",
    "\n",
    "print(\"  Merging gisaid (n=%d), pango (n=%d) and nextclade (n=%d) data together\" % (gisaid_df.shape[0], pango_df.shape[0], nextclade_df.shape[0]))\n",
    "Merge1 = pd.merge(gisaid_df, pango_df, how='inner', left_on='SeqID', right_on='taxon')\n",
    "Merge2 = pd.merge(Merge1, nextclade_df, how='inner', left_on='SeqID', right_on='seqName')\n",
    "print(\"  Total remaining records = %d\" % (Merge2.shape[0]))\n",
    "print(\"  Removing unwanted column headings from final summary file of samples sequenced\")\n",
    "gisaidcols = ['ref_genome_length']\n",
    "pangocols = (['pangoLEARN_version','taxon'])\n",
    "nextcladecols = ['seqName','qc.mixedSites.mixedSitesThreshold','qc.mixedSites.score','qc.mixedSites.status','qc.mixedSites.totalMixedSites','qc.privateMutations.cutoff','qc.missingData.missingDataThreshold','totalNonACGTNs','nonACGTNs']\n",
    "dropcols = gisaidcols + pangocols + nextcladecols\n",
    "sequenced_df = Merge2.drop(dropcols, axis=1)\n",
    "print(\"Done.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging sequenced samples with sample list...\n",
      "  No. samples...\n",
      "    ...in sample list: 755\n",
      "    ...with consensus sequence: 19\n",
      "    ...after merging: 755\n",
      "Done.\n",
      "\n",
      "Removing controls, unsequenced samples, those marked for exclusion or failing qc parameters\n",
      "    Samples remaining: 16\n",
      "Done\n",
      "\n",
      "Highlighting highest depth for duplicate samples...\n",
      "  Sample    No. dup.  Keep        Depth\n",
      "  Submittable samples: 16\n",
      "Done.\n",
      "\n",
      "Highlighting submittable samples\n",
      "Writing all sequencing data...\n",
      "    To: /media/dan/Master/WGS/5_GISAID/allsequencedata.tsv\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MERGE WITH SAMPLE LIST\n",
    "print(\"Merging sequenced samples with sample list...\")\n",
    "print(\"  No. samples...\")\n",
    "print(\"    ...in sample list: %d\" % seqsamples_df.shape[0])\n",
    "print(\"    ...with consensus sequence: %d\" % gisaid_df.shape[0])\n",
    "merged_df = pd.merge(left=seqsamples_df,\n",
    "                     right=sequenced_df,\n",
    "                     left_on=[\"SeqRun\", \"SeqBarcode\", \"SeqID\"],\n",
    "                     right_on=[\"SeqRun\", \"SeqBarcode\", \"SeqID\"],\n",
    "                    how='outer')\n",
    "print(\"    ...after merging: %d\" % merged_df.shape[0])\n",
    "print(\"Done.\")\n",
    "print(\"\")\n",
    "\n",
    "qc_depth = 50\n",
    "qc_breadth = 50\n",
    "\n",
    "print(\"Removing controls, unsequenced samples, those marked for exclusion or failing qc parameters\")\n",
    "keepers_df = merged_df.query(\"sequencing_depth_avg >= @qc_depth\" + \\\n",
    "                             \"& coverage_breadth >= @qc_breadth\" + \\\n",
    "                             \"& ExcludeSample != 'Y'\" + \\\n",
    "                             \"& Type == 'Sample'\" ,\n",
    "                             inplace=False)\n",
    "print(\"    Samples remaining: %d\" % keepers_df.shape[0])\n",
    "print(\"Done\")\n",
    "print(\"\")\n",
    "\n",
    "#Highlight duplicates\n",
    "print(\"Highlighting highest depth for duplicate samples...\")\n",
    "\n",
    "l_dfs = []\n",
    "print(\"  {:<8}  {:<8}  {:<10}  {:<4}\".format(\"Sample\", \"No. dup.\", \"Keep\", \"Depth\"))\n",
    "\n",
    "\n",
    "for n, sdf in keepers_df.groupby(\"SampleID\"):\n",
    "    n_dup = sdf.shape[0]\n",
    "    if n_dup > 1:\n",
    "        keep = sdf.sort_values(by =['GISAID_Accession_Number','coverage_breadth','sequencing_depth_avg'], \n",
    "                               ascending=[False,False,False], na_position='last').iloc[0]\n",
    "        print(\"  {:<8}  {:<8}  {:<10}  {:<4.1f}\".format(n, n_dup, keep[\"SampleID\"], keep[\"sequencing_depth_avg\"]))\n",
    "    else:\n",
    "        keep = sdf.iloc[0]\n",
    "    l_dfs.append(keep)\n",
    "keepers_df = pd.concat(l_dfs, 1).transpose()\n",
    "print(\"  Submittable samples: %d\" % keepers_df.shape[0])\n",
    "print(\"Done.\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Highlighting submittable samples\")\n",
    "keeperslist_df = keepers_df.filter(['SeqID','SeqRun','SeqBarcode'])\n",
    "keeperslist_df[\"Submittable\"] = True\n",
    "alldata_df = pd.merge(left=merged_df,\n",
    "                     right=keeperslist_df,\n",
    "                     left_on=[\"SeqRun\", \"SeqBarcode\", \"SeqID\"],\n",
    "                     right_on=[\"SeqRun\", \"SeqBarcode\", \"SeqID\"],\n",
    "                    how='outer')\n",
    "alldata_df = alldata_df.fillna({'Submittable' : False})\n",
    "alldata_df = alldata_df.drop('ExcludeSample', axis=1)\n",
    "\n",
    "#WRITE RESULTS\n",
    "print(\"Writing all sequencing data...\")\n",
    "output_fn = \"allsequencedata.tsv\"\n",
    "alldata_df.to_csv(os.path.join(gisaid_dir, output_fn), sep = '\\t', index=False)\n",
    "print(\"    To: %s\" % os.path.join(gisaid_dir, output_fn))\n",
    "print(\"Done.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Incorporating metadata...\n",
      "  Metadata identified for : 633 samples\n",
      "  Sequencing data for : 16 samples\n",
      "  Merging metadata with sequence data...\n",
      "Done\n",
      "  Total samples retained: 16\n"
     ]
    }
   ],
   "source": [
    "#Merging in metadata\n",
    "print(\"-\" * 80)\n",
    "print(\"Incorporating metadata...\")\n",
    "\n",
    "metadata_fn=\"Metadata.csv\"\n",
    "metadata_df = pd.read_csv(os.path.join(rampart_dir, metadata_fn))\n",
    "\n",
    "#Add in column highlighting any missing data\n",
    "check_cols = [\"Province\", \"District\", \"SpecimenDate\"] #List of key columns\n",
    "missing_data = [] #To house the new column of data\n",
    "for _, row in metadata_df.iterrows(): #Iterate over rows\n",
    "    m = [] #List to hold output from an individual column\n",
    "    for col in check_cols: #Iterate over columns we want to check\n",
    "        if row[col] != row[col]: #Only NaN is not equal to itself\n",
    "            m.append(col) #add data to list\n",
    "    missing_data.append(\", \".join(m)) #Join as a new string\n",
    "metadata_df[\"MissingMetadata\"] = missing_data\n",
    "\n",
    "print(\"  Metadata identified for : %d samples\" % metadata_df.shape[0])\n",
    "print(\"  Sequencing data for : %d samples\" % keepers_df.shape[0])\n",
    "print(\"  Merging metadata with sequence data...\")\n",
    "samplemeta_df = pd.merge(left=metadata_df,\n",
    "                     right=keepers_df,\n",
    "                     left_on=[\"SampleID\"],\n",
    "                     right_on=[\"SampleID\"],\n",
    "                    how='inner')\n",
    "print(\"Done\")\n",
    "print(\"  Total samples retained: %d\" % keepers_df.shape[0])\n",
    "\n",
    "#Drop uninformative columns\n",
    "samplemeta_df.drop(columns = ['Type','ExcludeSample'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All records have a SeqDate after the SpecimenDate\n",
      "\n",
      "  Writing out all sequence data with metadata...\n",
      "  To: /media/dan/Master/WGS/Samples_Sequenced_With_Metadata.csv\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Change from str to date\n",
    "samplemeta_df['SeqDate'] = pd.to_datetime(samplemeta_df['SeqDate'], format='%d/%m/%Y')\n",
    "samplemeta_df['SpecimenDate'] = pd.to_datetime(samplemeta_df['SpecimenDate'], format='%d/%m/%Y')\n",
    "#Sanity check on sample date and sequencing date\n",
    "samplemeta_df['DateCheck'] = samplemeta_df['SeqDate'] < samplemeta_df['SpecimenDate']\n",
    "if samplemeta_df['DateCheck'].unique().shape[0] > 1:\n",
    "    print(\"ERROR: %d records have a SeqDate before the SpecimenDate\" % samplemeta_df[samplemeta_df.DateCheck==False].shape[0])\n",
    "else:\n",
    "    print(\"All records have a SeqDate after the SpecimenDate\")\n",
    "    samplemeta_df.drop(columns = ['DateCheck'], inplace = True)\n",
    "print(\"\")\n",
    "\n",
    "#WRITE RESULTS\n",
    "print(\"  Writing out all sequence data with metadata...\")\n",
    "output_fn = \"Samples_Sequenced_With_Metadata.csv\"\n",
    "samplemeta_df.to_csv(os.path.join(data_dir, output_fn), sep = '\\t', index=False)\n",
    "print(\"  To: %s\" % os.path.join(data_dir, output_fn))\n",
    "print(\"Done.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Generating GISAID submission files\n",
      "Done\n",
      "  Writing out unfiltered gisaid submission file (includes sequences already submitted)...\n",
      "  To: /media/dan/Master/WGS/GISAID_Submission_Data_Unfiltered.csv\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 80)\n",
    "print(\"Generating GISAID submission files\")\n",
    "\n",
    "#Pull out the year\n",
    "samplemeta_df[\"Year\"] = samplemeta_df['SpecimenDate'].dt.year.astype('Int64')\n",
    "#Generate a Province / District location\n",
    "l = []\n",
    "for _, row in samplemeta_df[['Province','District']].iterrows():\n",
    "    l.append(pd.Series(row).str.cat(sep='/'))\n",
    "samplemeta_df[\"Location\"] = pd.DataFrame(l)\n",
    "#Fill in NA entries and replace keys with correct values\n",
    "samplemeta_df['Sex'].fillna(value=\"Unknown\", inplace=True)\n",
    "samplemeta_df['Sex'].replace({\"M\":\"Male\",\"F\":\"Female\"}, inplace = True)\n",
    "samplemeta_df['Age'].fillna(value=\"Unknown\", inplace=True) \n",
    "samplemeta_df['PatientStatus'].fillna(value=\"Unknown\", inplace=True)\n",
    "\n",
    "#Create an empty dataframe with length of samplemeta_df\n",
    "submit_df = pd.DataFrame(index=np.arange(samplemeta_df.shape[0]), columns=np.arange(0))\n",
    "# pd.DataFrame(index=np.arange(1), columns=np.arange(8))\n",
    "submit_df[\"GISAID_Accession_Number\"] = samplemeta_df['GISAID_Accession_Number']\n",
    "submit_df[\"SeqID\"] = samplemeta_df['SeqID']\n",
    "submit_df[\"submitter\"] = \"djbridges\"\n",
    "submit_df[\"fn\"] = \"filename\"\n",
    "submit_df[\"covv_virus_name\"] = \"hCoV-19/Zambia/ZMB-\"+ samplemeta_df['SampleID'].astype('str') + \"/\" + samplemeta_df['Year'].astype('str')\n",
    "submit_df[\"covv_type\"] = \"betacoronavirus\"\n",
    "submit_df[\"covv_passage\"] = \"Original\"\n",
    "submit_df[\"covv_collection_date\"] = samplemeta_df['SpecimenDate']\n",
    "submit_df[\"covv_location\"] = \"Africa/Zambia/\" + samplemeta_df['Location']\n",
    "submit_df[\"covv_add_location\"] = \"\"\n",
    "submit_df[\"covv_host\"] = \"Human\"\n",
    "submit_df[\"covv_add_host_info\"] = \"\"\n",
    "submit_df[\"covv_gender\"] = samplemeta_df['Sex']\n",
    "submit_df[\"covv_patient_age\"] = samplemeta_df['Age']\n",
    "submit_df[\"covv_patient_status\"] = samplemeta_df['PatientStatus']\n",
    "submit_df[\"covv_specimen\"] = \"Nasopharyngeal swab\"\n",
    "submit_df[\"covv_outbreak\"] = \"\"\n",
    "submit_df[\"covv_last_vaccinated\"] = \"\"\n",
    "submit_df[\"covv_treatment\"] = \"\"\n",
    "submit_df[\"covv_seq_technology\"] = \"Nanopore MinION\"\n",
    "submit_df[\"covv_assembly_method\"] = \"ARTIC Field Workflow\"\n",
    "submit_df[\"covv_coverage\"] = samplemeta_df['sequencing_depth_avg'].astype('int')\n",
    "submit_df[\"covv_orig_lab\"] = \"University of Zambia, School of Veterinary Medicine\"\n",
    "submit_df[\"covv_orig_lab_addr\"] = \"University of Zambia, School of Veterinary Medicine, Gt East Road Campus, Lusaka, Zambia\"\n",
    "submit_df[\"covv_provider_sample_id\"] = \"\"\n",
    "submit_df[\"covv_subm_lab\"] = \"UNZAVET and PATH\"\n",
    "submit_df[\"covv_subm_lab_addr\"] = \"University of Zambia, School of Veterinary Medicine, Gt East Road Campus, Lusaka, Zambia\"\n",
    "submit_df[\"covv_subm_sample_id\"] = samplemeta_df[\"SampleID\"]\n",
    "submit_df[\"covv_authors\"] = \"Mulenga Mwenda-Chimfwembe, Ngonda Saasa, Daniel Bridges\"\n",
    "submit_df[\"covv_comment\"] = \"\"\n",
    "submit_df[\"comment_type\"] =\"\"\n",
    "print(\"Done\")\n",
    "\n",
    "#WRITE RESULTS\n",
    "print(\"  Writing out unfiltered gisaid submission file (includes sequences already submitted)...\")\n",
    "output_fn = \"GISAID_Submission_Data_Unfiltered.csv\"\n",
    "submit_df.to_csv(os.path.join(data_dir, output_fn), sep = ',', index=False)\n",
    "print(\"  To: %s\" % os.path.join(data_dir, output_fn))\n",
    "print(\"Done.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Summarising output per run...\n",
      "  For all samples added to a sequencing run\n",
      "  For all samples with a consensus\n",
      "  For all samples with depth >50X and breadth >50% \n",
      "  Done\n",
      "  Writing results...\n",
      "  To: /media/dan/Master/WGS/5_GISAID/runsummary.csv\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculate per run summaries\n",
    "print(\"-\" * 80)\n",
    "print(\"Summarising output per run...\")\n",
    "print(\"  For all samples added to a sequencing run\")\n",
    "sample_sum = seqsamples_df.groupby(\"SeqRun\").agg(\n",
    "    samples=('SeqID', 'count')\n",
    ")\n",
    "\n",
    "print(\"  For all samples with a consensus\")\n",
    "sequenced_sum = sequenced_df.groupby('SeqRun').agg(\n",
    "    all_consensus=('SeqID','count'),\n",
    "    all_depth_min=('assembly_coverage_depth',min),\n",
    "    all_depth_max=('assembly_coverage_depth',max),\n",
    "    all_score_mean=('qc.overallScore','mean')\n",
    ")\n",
    "\n",
    "print(\"  For all samples with depth >{:<2}X and breadth >{:<2}% \".format(qc_depth, qc_breadth))\n",
    "qc = sequenced_df[(sequenced_df.sequencing_depth_avg > qc_depth) & \n",
    "                    (sequenced_df.coverage_breadth > qc_breadth)]\n",
    "qc_sum = qc.groupby('SeqRun').agg(\n",
    "    qc_consensus=('SeqID','count'),\n",
    "    qc_depth_min=('assembly_coverage_depth',min),\n",
    "    qc_depth_max=('assembly_coverage_depth',max),\n",
    "    qc_score_mean=('qc.overallScore','mean')\n",
    ")\n",
    "\n",
    "#Merge datasets together\n",
    "sum1_df = pd.merge(left=sample_sum,\n",
    "                     right=sequenced_sum,\n",
    "                     left_on=[\"SeqRun\"],\n",
    "                     right_on=[\"SeqRun\"],\n",
    "                     how=\"outer\")\n",
    "sum1_df['all_success'] = sum1_df['all_consensus']/sum1_df['samples']\n",
    "\n",
    "runsummary_df = pd.merge(left=sum1_df,\n",
    "                     right=qc_sum,\n",
    "                     left_on=[\"SeqRun\"],\n",
    "                     right_on=[\"SeqRun\"],\n",
    "                     how=\"outer\")\n",
    "runsummary_df['qc_success'] = runsummary_df['qc_consensus']/runsummary_df['samples']\n",
    "\n",
    "#Create dataframes for barcoded and unclassified reads per run\n",
    "bc = gisaid_df[['SeqRun','total_reads']].groupby('SeqRun').sum()\n",
    "bc.rename(columns = {'total_reads':'barcoded_reads'}, inplace = True)\n",
    "un = pd.DataFrame(dtr).groupby('SeqRun').sum()\n",
    "un.rename(columns = {'total_reads':'unclassified_reads'}, inplace = True)\n",
    "#Merge into runsummary_df\n",
    "runsummary_df = pd.merge(left=runsummary_df,\n",
    "                     right=bc,\n",
    "                     left_on=[\"SeqRun\"],\n",
    "                     right_on=[\"SeqRun\"],\n",
    "                     how=\"outer\")\n",
    "runsummary_df = pd.merge(left=runsummary_df,\n",
    "                     right=un,\n",
    "                     left_on=[\"SeqRun\"],\n",
    "                     right_on=[\"SeqRun\"],\n",
    "                     how=\"outer\")\n",
    "#Calculate barcoding efficiency\n",
    "runsummary_df[\"barcoding_efficiency\"] = runsummary_df['barcoded_reads'] / (runsummary_df['unclassified_reads'] + runsummary_df['barcoded_reads'])\n",
    "\n",
    "print(\"  Done\")\n",
    "\n",
    "# WRITE RESULTS\n",
    "print(\"  Writing results...\")\n",
    "runsummary_fn = \"runsummary.csv\"\n",
    "runsummary_df.to_csv(os.path.join(gisaid_dir, runsummary_fn), index=True)\n",
    "#df.to_csv('Students.csv', sep ='\\t')\n",
    "print(\"  To: %s\" % os.path.join(gisaid_dir, runsummary_fn))\n",
    "print(\"Done.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Runtime: 0:04:06.323298\n",
      "Finished at: 2021-05-19 10:08:05\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 80)\n",
    "print(\"Runtime: %s\" % str(datetime.timedelta(seconds=time.time() - start_time)))\n",
    "print(\"Finished at: %s\" % datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples</th>\n",
       "      <th>all_consensus</th>\n",
       "      <th>all_depth_min</th>\n",
       "      <th>all_depth_max</th>\n",
       "      <th>all_score_mean</th>\n",
       "      <th>all_success</th>\n",
       "      <th>qc_consensus</th>\n",
       "      <th>qc_depth_min</th>\n",
       "      <th>qc_depth_max</th>\n",
       "      <th>qc_score_mean</th>\n",
       "      <th>qc_success</th>\n",
       "      <th>barcoded_reads</th>\n",
       "      <th>unclassified_reads</th>\n",
       "      <th>barcoding_efficiency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SeqRun</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C01</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C02</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C03</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C04</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C05</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C06</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C07</th>\n",
       "      <td>20</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.597148</td>\n",
       "      <td>453.235423</td>\n",
       "      <td>1317.834067</td>\n",
       "      <td>0.95</td>\n",
       "      <td>16.0</td>\n",
       "      <td>78.632289</td>\n",
       "      <td>453.235423</td>\n",
       "      <td>161.360517</td>\n",
       "      <td>0.8</td>\n",
       "      <td>452885.0</td>\n",
       "      <td>868387.0</td>\n",
       "      <td>0.342764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C08</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C09</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C11</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C12</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C13</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C14</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C15</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C16</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C17</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C18</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C19</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C20</th>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C21</th>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C22</th>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C23</th>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C24</th>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C25</th>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C26</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C27</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        samples  all_consensus  all_depth_min  all_depth_max  all_score_mean  \\\n",
       "SeqRun                                                                         \n",
       "C01           4            NaN            NaN            NaN             NaN   \n",
       "C02           5            NaN            NaN            NaN             NaN   \n",
       "C03          22            NaN            NaN            NaN             NaN   \n",
       "C04          12            NaN            NaN            NaN             NaN   \n",
       "C05          24            NaN            NaN            NaN             NaN   \n",
       "C06           4            NaN            NaN            NaN             NaN   \n",
       "C07          20           19.0      29.597148     453.235423     1317.834067   \n",
       "C08           4            NaN            NaN            NaN             NaN   \n",
       "C09          24            NaN            NaN            NaN             NaN   \n",
       "C10          24            NaN            NaN            NaN             NaN   \n",
       "C11          24            NaN            NaN            NaN             NaN   \n",
       "C12          24            NaN            NaN            NaN             NaN   \n",
       "C13          24            NaN            NaN            NaN             NaN   \n",
       "C14          24            NaN            NaN            NaN             NaN   \n",
       "C15          24            NaN            NaN            NaN             NaN   \n",
       "C16          24            NaN            NaN            NaN             NaN   \n",
       "C17          24            NaN            NaN            NaN             NaN   \n",
       "C18          24            NaN            NaN            NaN             NaN   \n",
       "C19          24            NaN            NaN            NaN             NaN   \n",
       "C20          35            NaN            NaN            NaN             NaN   \n",
       "C21          49            NaN            NaN            NaN             NaN   \n",
       "C22          87            NaN            NaN            NaN             NaN   \n",
       "C23          79            NaN            NaN            NaN             NaN   \n",
       "C24          46            NaN            NaN            NaN             NaN   \n",
       "C25          71            NaN            NaN            NaN             NaN   \n",
       "C26          20            NaN            NaN            NaN             NaN   \n",
       "C27           9            NaN            NaN            NaN             NaN   \n",
       "\n",
       "        all_success  qc_consensus  qc_depth_min  qc_depth_max  qc_score_mean  \\\n",
       "SeqRun                                                                         \n",
       "C01             NaN           NaN           NaN           NaN            NaN   \n",
       "C02             NaN           NaN           NaN           NaN            NaN   \n",
       "C03             NaN           NaN           NaN           NaN            NaN   \n",
       "C04             NaN           NaN           NaN           NaN            NaN   \n",
       "C05             NaN           NaN           NaN           NaN            NaN   \n",
       "C06             NaN           NaN           NaN           NaN            NaN   \n",
       "C07            0.95          16.0     78.632289    453.235423     161.360517   \n",
       "C08             NaN           NaN           NaN           NaN            NaN   \n",
       "C09             NaN           NaN           NaN           NaN            NaN   \n",
       "C10             NaN           NaN           NaN           NaN            NaN   \n",
       "C11             NaN           NaN           NaN           NaN            NaN   \n",
       "C12             NaN           NaN           NaN           NaN            NaN   \n",
       "C13             NaN           NaN           NaN           NaN            NaN   \n",
       "C14             NaN           NaN           NaN           NaN            NaN   \n",
       "C15             NaN           NaN           NaN           NaN            NaN   \n",
       "C16             NaN           NaN           NaN           NaN            NaN   \n",
       "C17             NaN           NaN           NaN           NaN            NaN   \n",
       "C18             NaN           NaN           NaN           NaN            NaN   \n",
       "C19             NaN           NaN           NaN           NaN            NaN   \n",
       "C20             NaN           NaN           NaN           NaN            NaN   \n",
       "C21             NaN           NaN           NaN           NaN            NaN   \n",
       "C22             NaN           NaN           NaN           NaN            NaN   \n",
       "C23             NaN           NaN           NaN           NaN            NaN   \n",
       "C24             NaN           NaN           NaN           NaN            NaN   \n",
       "C25             NaN           NaN           NaN           NaN            NaN   \n",
       "C26             NaN           NaN           NaN           NaN            NaN   \n",
       "C27             NaN           NaN           NaN           NaN            NaN   \n",
       "\n",
       "        qc_success  barcoded_reads  unclassified_reads  barcoding_efficiency  \n",
       "SeqRun                                                                        \n",
       "C01            NaN             NaN                 NaN                   NaN  \n",
       "C02            NaN             NaN                 NaN                   NaN  \n",
       "C03            NaN             NaN                 NaN                   NaN  \n",
       "C04            NaN             NaN                 NaN                   NaN  \n",
       "C05            NaN             NaN                 NaN                   NaN  \n",
       "C06            NaN             NaN                 NaN                   NaN  \n",
       "C07            0.8        452885.0            868387.0              0.342764  \n",
       "C08            NaN             NaN                 NaN                   NaN  \n",
       "C09            NaN             NaN                 NaN                   NaN  \n",
       "C10            NaN             NaN                 NaN                   NaN  \n",
       "C11            NaN             NaN                 NaN                   NaN  \n",
       "C12            NaN             NaN                 NaN                   NaN  \n",
       "C13            NaN             NaN                 NaN                   NaN  \n",
       "C14            NaN             NaN                 NaN                   NaN  \n",
       "C15            NaN             NaN                 NaN                   NaN  \n",
       "C16            NaN             NaN                 NaN                   NaN  \n",
       "C17            NaN             NaN                 NaN                   NaN  \n",
       "C18            NaN             NaN                 NaN                   NaN  \n",
       "C19            NaN             NaN                 NaN                   NaN  \n",
       "C20            NaN             NaN                 NaN                   NaN  \n",
       "C21            NaN             NaN                 NaN                   NaN  \n",
       "C22            NaN             NaN                 NaN                   NaN  \n",
       "C23            NaN             NaN                 NaN                   NaN  \n",
       "C24            NaN             NaN                 NaN                   NaN  \n",
       "C25            NaN             NaN                 NaN                   NaN  \n",
       "C26            NaN             NaN                 NaN                   NaN  \n",
       "C27            NaN             NaN                 NaN                   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runsummary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
